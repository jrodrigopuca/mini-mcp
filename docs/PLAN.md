# Plan: Mini-MCP para AnÃ¡lisis de Datos con Lenguaje Natural

## ğŸ¯ Objetivo

Crear un servidor MCP (Model Context Protocol) extensible, seguro y configurable que permita analizar archivos de datos (CSV, JSON, Parquet, etc.) mediante consultas SQL o lenguaje natural, usando **DuckDB** en memoria como motor de consultas analÃ­ticas.

---

## ğŸ›¡ï¸ Principios de DiseÃ±o

| Principio             | ImplementaciÃ³n                                    |
| --------------------- | ------------------------------------------------- |
| **Seguridad primero** | Read-only por defecto, operaciones limitadas      |
| **Configurable**      | Archivo de configuraciÃ³n para lÃ­mites y permisos  |
| **ValidaciÃ³n**        | Inferencia y validaciÃ³n de esquema antes de carga |
| **LÃ­mites claros**    | MÃ¡ximo de filas, tamaÃ±o de salida, timeout        |
| **Extensible**        | Parsers/exporters modulares                       |

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            Mini-MCP Server                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚  â”‚     Config      â”‚   â”‚    Security     â”‚                                  â”‚
â”‚  â”‚  ğŸŸ¡ Configurable â”‚   â”‚  ğŸ”´ Hardcoded   â”‚                                  â”‚
â”‚  â”‚  (lÃ­mites, rutas)â”‚   â”‚  (SQL, paths)   â”‚                                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚           â”‚                     â”‚                                           â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
â”‚                      â–¼                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚    Parsers    â”‚  â”‚    DuckDB     â”‚  â”‚   Exporters   â”‚  â”‚ Visualizers â”‚  â”‚
â”‚  â”‚ + Schema Inf. â”‚â”€â–ºâ”‚   (memoria)   â”‚â”€â–ºâ”‚   (salida)    â”‚  â”‚ ASCII/Merm. â”‚  â”‚
â”‚  â”‚   Validators  â”‚  â”‚   READ-ONLY   â”‚  â”‚ CSV,JSON,JSONLâ”‚  â”‚             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                   â”‚               â”‚           â”‚
â”‚    CSV, JSON,               â”‚                   â”‚               â”‚           â”‚
â”‚    TSV, Parquet        â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”              â”‚               â”‚           â”‚
â”‚                        â”‚   NLP   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                        â”‚ NLâ†’SQL  â”‚                                          â”‚
â”‚                        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                          â”‚
â”‚                             â”‚                                               â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                                        â”‚
â”‚                      â”‚    Tools    â”‚                                        â”‚
â”‚                      â”‚    (MCP)    â”‚                                        â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                        â”‚
â”‚                             â”‚                                               â”‚
â”‚         load_data, query_data, describe_data, list_tables,                  â”‚
â”‚                    export_data, visualize_data                              â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de transformaciÃ³n

```
  Entrada           Procesamiento            Salida
  â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”€â”€â”€â”€â”€â”€

  archivo.csv  â”€â”                        â”Œâ”€â–º resultado.json
  datos.json   â”€â”¼â”€â”€â–º DuckDB â”€â”€â–º Query â”€â”€â”€â”¼â”€â–º export.csv
  info.tsv     â”€â”˜    (merge)    (SQL)    â””â”€â–º stream.jsonl
```

### Ventajas de esta arquitectura

| Aspecto                 | Beneficio                                                               |
| ----------------------- | ----------------------------------------------------------------------- |
| **DuckDB**              | 10-100x mÃ¡s rÃ¡pido que SQLite para agregaciones, soporte Parquet nativo |
| **Seguridad 3 niveles** | ğŸ”´ Hardcoded + ğŸŸ¡ Configurable + ğŸŸ¢ Flexible                            |
| **ValidaciÃ³n**          | Inferencia de esquema y reporte de calidad antes de cargar              |
| **Read-only**           | Seguro por defecto, sin modificaciones accidentales                     |
| **Extensible**          | Agregar formatos solo requiere nuevo parser/exporter                    |
| **VisualizaciÃ³n**       | ASCII (terminal) + Mermaid (markdown) sin dependencias                  |
| **NLP â†’ SQL**           | Consultas en lenguaje natural traducidas a SQL                          |

---

## ğŸ“‹ Fases del Proyecto

### Fase 1: ConfiguraciÃ³n Base âœ…

**Tiempo estimado: 1-2 horas** | **Estado: COMPLETADO**

- [x] Configurar TypeScript
- [x] Instalar dependencias (MCP SDK, DuckDB, parsers)
- [x] Configurar estructura de carpetas
- [x] Crear servidor MCP bÃ¡sico
- [x] Crear archivo de configuraciÃ³n por defecto

**Estructura propuesta:**

```
mini-mcp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Punto de entrada del servidor MCP
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ index.ts          # Carga y valida configuraciÃ³n
â”‚   â”‚   â”œâ”€â”€ schema.ts         # Schema Zod para config
â”‚   â”‚   â”œâ”€â”€ validator.ts      # ValidaciÃ³n con advertencias
â”‚   â”‚   â””â”€â”€ defaults.ts       # Valores por defecto
â”‚   â”œâ”€â”€ security/
â”‚   â”‚   â”œâ”€â”€ hardcoded.ts      # ğŸ”´ Protecciones NO configurables
â”‚   â”‚   â””â”€â”€ enforcer.ts       # AplicaciÃ³n de reglas de seguridad
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â”œâ”€â”€ load-data.ts      # Tool: cargar archivos
â”‚   â”‚   â”œâ”€â”€ query-data.ts     # Tool: consultas SQL/NL
â”‚   â”‚   â”œâ”€â”€ describe-data.ts  # Tool: estadÃ­sticas
â”‚   â”‚   â”œâ”€â”€ list-tables.ts    # Tool: listar tablas cargadas
â”‚   â”‚   â”œâ”€â”€ export-data.ts    # Tool: exportar/transformar datos
â”‚   â”‚   â””â”€â”€ visualize-data.ts # Tool: visualizar datos
â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”œâ”€â”€ index.ts          # Registry de parsers
â”‚   â”‚   â”œâ”€â”€ base-parser.ts    # Interface comÃºn
â”‚   â”‚   â”œâ”€â”€ csv-parser.ts     # Parser CSV/TSV
â”‚   â”‚   â”œâ”€â”€ json-parser.ts    # Parser JSON/JSONL
â”‚   â”‚   â””â”€â”€ parquet-parser.ts # Parser Parquet (DuckDB nativo)
â”‚   â”œâ”€â”€ validators/
â”‚   â”‚   â”œâ”€â”€ index.ts          # Validador principal
â”‚   â”‚   â”œâ”€â”€ schema-inferrer.ts # Inferencia de esquema
â”‚   â”‚   â””â”€â”€ data-validator.ts  # ValidaciÃ³n de datos vs esquema
â”‚   â”œâ”€â”€ exporters/
â”‚   â”‚   â”œâ”€â”€ index.ts          # Registry de exporters
â”‚   â”‚   â”œâ”€â”€ base-exporter.ts  # Interface comÃºn
â”‚   â”‚   â”œâ”€â”€ csv-exporter.ts   # Exportar a CSV
â”‚   â”‚   â”œâ”€â”€ json-exporter.ts  # Exportar a JSON
â”‚   â”‚   â””â”€â”€ jsonl-exporter.ts # Exportar a JSONL (streaming)
â”‚   â”œâ”€â”€ visualizers/
â”‚   â”‚   â”œâ”€â”€ index.ts          # Registry de visualizers
â”‚   â”‚   â”œâ”€â”€ base-visualizer.ts # Interface comÃºn
â”‚   â”‚   â”œâ”€â”€ ascii-charts.ts   # GrÃ¡ficos ASCII (barras, histogramas)
â”‚   â”‚   â””â”€â”€ mermaid-charts.ts # GrÃ¡ficos Mermaid (pie, bar, line)
â”‚   â”œâ”€â”€ store/
â”‚   â”‚   â””â”€â”€ data-store.ts     # GestiÃ³n de DuckDB en memoria (READ-ONLY)
â”‚   â”œâ”€â”€ nlp/
â”‚   â”‚   â””â”€â”€ query-builder.ts  # NL â†’ SQL translator
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ index.ts          # Definiciones de tipos
â”œâ”€â”€ mini-mcp.config.json      # ConfiguraciÃ³n del servidor
â”œâ”€â”€ mini-mcp.schema.json      # JSON Schema para validaciÃ³n de config
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ README.md
```

---

### Fase 2: Sistema de ConfiguraciÃ³n âœ…

**Tiempo estimado: 2 horas** | **Estado: COMPLETADO**

- [x] Definir schema de configuraciÃ³n con Zod
- [x] Implementar carga de `mini-mcp.config.json`
- [x] Valores por defecto seguros
- [x] ValidaciÃ³n al iniciar servidor con advertencias
- [x] Hardcodear protecciones crÃ­ticas (no configurables)

#### Niveles de Seguridad

| Nivel        | Color | Configurable       | DescripciÃ³n                                      |
| ------------ | ----- | ------------------ | ------------------------------------------------ |
| **CrÃ­tico**  | ğŸ”´    | âŒ Nunca           | Hardcoded en cÃ³digo, previene daÃ±o irreversible  |
| **Sensible** | ğŸŸ¡    | âš ï¸ Con advertencia | Usuario puede cambiar, se muestra warning        |
| **Flexible** | ğŸŸ¢    | âœ… Libremente      | Sin riesgo de seguridad, ajustar segÃºn necesidad |

#### ğŸ”´ Protecciones HARDCODED (no en config)

```typescript
// src/security/hardcoded.ts
// ESTAS PROTECCIONES NO SON CONFIGURABLES - SIEMPRE ACTIVAS

export const ALWAYS_BLOCKED_SQL = [
	"DROP",
	"DELETE",
	"TRUNCATE",
	"ALTER",
	"CREATE",
	"INSERT",
	"UPDATE",
	"ATTACH",
	"DETACH",
	"EXEC",
	"EXECUTE",
	"PRAGMA",
	"VACUUM",
	"REINDEX",
];

export const ALWAYS_BLOCKED_PATHS = [
	"../", // Path traversal
	"..\\", // Path traversal Windows
	"/etc/passwd",
	"/etc/shadow",
	"~/.ssh",
	".env",
	".git",
];

export const SECURITY_RULES = {
	// Nombres de tabla sanitizados (solo alfanumÃ©rico y _)
	tableNameRegex: /^[a-zA-Z_][a-zA-Z0-9_]*$/,

	// MÃ¡ximo absoluto de filas (incluso si config dice mÃ¡s)
	absoluteMaxRows: 10_000_000,

	// MÃ¡ximo absoluto de archivo (incluso si config dice mÃ¡s)
	absoluteMaxFileSizeMB: 2048,
};
```

#### Archivo de configuraciÃ³n: `mini-mcp.config.json`

```json
{
	"$schema": "./mini-mcp.schema.json",

	// === ğŸŸ¡ SEGURIDAD (configurable con advertencia) ===
	"security": {
		"readOnly": true, // âš ï¸ false permite escribir archivos
		"allowedPaths": [
			// âš ï¸ ampliar da mÃ¡s acceso al filesystem
			"./data",
			"/Users/*/Documents/data"
		],
		"blockedPaths": [
			// Rutas adicionales a bloquear (+ hardcoded)
			"/var",
			"/tmp"
		],
		"allowNetworkPaths": false, // âš ï¸ true permite URLs http/https
		"maxFileSizeMB": 100 // âš ï¸ mayor = mÃ¡s riesgo de memoria
	},

	// === ğŸŸ¢ LÃMITES DE OUTPUT (libremente configurable) ===
	"limits": {
		"maxRowsInMemory": 1000000, // MÃ¡ximo filas en una tabla
		"maxRowsOutput": 1000, // MÃ¡ximo filas en respuesta de query
		"maxOutputChars": 50000, // MÃ¡ximo caracteres en respuesta
		"maxTablesLoaded": 10, // MÃ¡ximo tablas simultÃ¡neas
		"queryTimeoutMs": 30000, // Timeout para queries (30s)
		"maxChartDataPoints": 50 // MÃ¡ximo puntos en visualizaciones
	},

	// === ğŸŸ¢ OPERACIONES PERMITIDAS (libremente configurable) ===
	"operations": {
		"allowLoad": true, // Permitir cargar archivos
		"allowQuery": true, // Permitir queries SQL
		"allowNaturalLanguage": true, // Permitir NL â†’ SQL
		"allowDescribe": true, // Permitir describe/stats
		"allowExport": false, // Requiere readOnly: false
		"allowVisualize": true // Permitir generar grÃ¡ficos
	},

	// === ğŸŸ¢ FORMATOS (libremente configurable) ===
	"formats": {
		"input": ["csv", "tsv", "json", "jsonl", "parquet"],
		"output": ["json", "csv", "jsonl"],
		"visualization": ["ascii", "mermaid"]
	},

	// === ğŸŸ¢ DUCKDB (libremente configurable) ===
	"duckdb": {
		"memoryLimitMB": 512, // LÃ­mite de memoria para DuckDB
		"threads": 2 // NÃºmero de threads
	}
}
```

**Nota:** Los `blockedSQLKeywords` NO estÃ¡n en config porque son hardcoded.

#### ValidaciÃ³n con Advertencias

```typescript
// src/config/validator.ts
import {
	ALWAYS_BLOCKED_PATHS,
	ALWAYS_BLOCKED_SQL,
} from "../security/hardcoded";

export function validateAndWarn(config: Config): ValidationResult {
	const warnings: string[] = [];
	const errors: string[] = [];

	// === ADVERTENCIAS (ğŸŸ¡ configuraciÃ³n sensible) ===

	if (!config.security.readOnly) {
		warnings.push(
			"âš ï¸  ADVERTENCIA: readOnly: false",
			"    El MCP puede escribir archivos en disco.",
			"    AsegÃºrese de que allowedPaths estÃ¡ correctamente configurado.",
		);
	}

	if (config.security.allowNetworkPaths) {
		warnings.push(
			"âš ï¸  ADVERTENCIA: allowNetworkPaths: true",
			"    El MCP puede acceder a URLs externas (http/https).",
			"    Esto podrÃ­a exponer datos o permitir SSRF.",
		);
	}

	// Detectar paths muy amplios
	const dangerousPaths = config.security.allowedPaths.filter(
		(p) => p === "/" || p === "~" || p === "*" || p === "/**",
	);
	if (dangerousPaths.length > 0) {
		warnings.push(
			"âš ï¸  ADVERTENCIA: allowedPaths contiene rutas muy amplias",
			`    Paths: ${dangerousPaths.join(", ")}`,
			"    Esto da acceso a gran parte del filesystem.",
		);
	}

	if (config.security.maxFileSizeMB > 500) {
		warnings.push(
			"âš ï¸  ADVERTENCIA: maxFileSizeMB > 500MB",
			"    Archivos muy grandes pueden causar problemas de memoria.",
		);
	}

	// === VALIDACIÃ“N DE CONSISTENCIA ===

	if (config.operations.allowExport && config.security.readOnly) {
		errors.push(
			"âŒ ERROR: allowExport: true requiere readOnly: false",
			"   Cambie readOnly a false o deshabilite allowExport.",
		);
	}

	// === OUTPUT ===

	if (warnings.length > 0) {
		console.warn("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
		console.warn("â•‘     ADVERTENCIAS DE CONFIGURACIÃ“N        â•‘");
		console.warn("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
		warnings.forEach((w) => console.warn(w));
		console.warn(
			"\nEstas configuraciones son intencionales? (continÃºa en 3s...)\n",
		);
	}

	if (errors.length > 0) {
		console.error("\nâŒ ERRORES DE CONFIGURACIÃ“N:");
		errors.forEach((e) => console.error(e));
		throw new Error("ConfiguraciÃ³n invÃ¡lida. Corrija los errores.");
	}

	return { warnings, errors, isValid: errors.length === 0 };
}
```

#### AplicaciÃ³n de Protecciones Hardcoded

```typescript
// src/security/enforcer.ts
import {
	ALWAYS_BLOCKED_SQL,
	ALWAYS_BLOCKED_PATHS,
	SECURITY_RULES,
} from "./hardcoded";

export class SecurityEnforcer {
	// Siempre bloquea estos SQL keywords, sin importar config
	validateSQL(sql: string): void {
		const upperSQL = sql.toUpperCase();
		for (const keyword of ALWAYS_BLOCKED_SQL) {
			// Buscar keyword como palabra completa
			const regex = new RegExp(`\\b${keyword}\\b`, "i");
			if (regex.test(upperSQL)) {
				throw new SecurityError(
					`SQL bloqueado: contiene '${keyword}'`,
					"BLOCKED_SQL_KEYWORD",
				);
			}
		}
	}

	// Siempre bloquea estos paths, sin importar config
	validatePath(path: string): void {
		for (const blocked of ALWAYS_BLOCKED_PATHS) {
			if (path.includes(blocked)) {
				throw new SecurityError(
					`Ruta bloqueada por seguridad: '${blocked}'`,
					"BLOCKED_PATH",
				);
			}
		}
	}

	// Sanitizar nombre de tabla
	sanitizeTableName(name: string): string {
		if (!SECURITY_RULES.tableNameRegex.test(name)) {
			// Limpiar caracteres no permitidos
			const sanitized = name.replace(/[^a-zA-Z0-9_]/g, "_");
			console.warn(`Nombre de tabla sanitizado: '${name}' â†’ '${sanitized}'`);
			return sanitized;
		}
		return name;
	}
}
```

---

### Fase 3: DataStore con DuckDB âœ…

**Tiempo estimado: 2-3 horas** | **Estado: COMPLETADO**

- [x] Configurar `@duckdb/node-api` (nuevo paquete oficial)
- [x] Implementar clase `DuckDBStore` READ-ONLY:
  - Crear tablas dinÃ¡micamente desde datos parseados
  - Detectar tipos de columnas (VARCHAR, INTEGER, DOUBLE, BOOLEAN, DATE, TIMESTAMP, BIGINT)
  - Ejecutar queries SQL con lÃ­mites configurables
  - Listar tablas y esquemas (`getTableMetadata()`)
  - Obtener estadÃ­sticas (`getTableStats()`)
  - Aplicar lÃ­mites de configuraciÃ³n
- [x] Validar SQL contra keywords permitidos/bloqueados
- [x] Manejar mÃºltiples tablas simultÃ¡neas

**Nota:** Se usÃ³ `@duckdb/node-api` en lugar de `duckdb` por mejor soporte ESM.

```typescript
// src/store/data-store.ts
import * as duckdb from "duckdb";

class DataStore {
	private db: duckdb.Database;
	private config: Config;

	constructor(config: Config) {
		this.config = config;
		this.db = new duckdb.Database(":memory:", {
			max_memory: `${config.duckdb.memoryLimitMB}MB`,
			threads: config.duckdb.threads,
		});
	}

	// Crear tabla desde datos parseados
	async createTable(
		name: string,
		columns: ColumnDef[],
		data: any[],
	): Promise<void>;

	// Ejecutar query con validaciÃ³n y lÃ­mites
	async query(sql: string): Promise<QueryResult> {
		this.validateSQL(sql); // Bloquear keywords peligrosos
		// Aplicar LIMIT automÃ¡tico si no tiene
		// Aplicar timeout
		// Truncar output si excede maxOutputChars
	}

	// Validar SQL contra config
	private validateSQL(sql: string): void {
		const blocked = this.config.operations.blockedSQLKeywords;
		for (const keyword of blocked) {
			if (sql.toUpperCase().includes(keyword)) {
				throw new Error(`SQL keyword "${keyword}" no estÃ¡ permitido`);
			}
		}
	}

	getTables(): TableInfo[];
	getSchema(table: string): ColumnDef[];
	dropTable(name: string): void;
}
```

---

### Fase 4: Sistema de Parsers + ValidaciÃ³n de Esquema âœ…

**Tiempo estimado: 3 horas** | **Estado: COMPLETADO**

- [x] Crear interface `DataParser`
- [x] Implementar `CSVParser` con `csv-parse` (auto-detecciÃ³n de delimitador)
- [x] Implementar `JSONParser` (JSON arrays y JSONL)
- [x] Implementar `SchemaValidator` con inferencia de tipos
- [x] Implementar `ParquetParser` (DuckDB nativo)
- [x] Auto-detectar formato por extensiÃ³n (`detectFormat()`)
- [x] **Inferencia de esquema** (`inferColumnTypes()`)
- [x] **ValidaciÃ³n de datos** contra esquema inferido

```typescript
// src/parsers/base-parser.ts
interface DataParser {
	readonly supportedExtensions: string[];

	// Inferir esquema leyendo solo las primeras N filas
	inferSchema(filePath: string, sampleRows?: number): Promise<InferredSchema>;

	// Parsear completo con validaciÃ³n
	parse(filePath: string, options?: ParserOptions): Promise<ParsedData>;
}

interface InferredSchema {
	columns: ColumnDef[];
	sampleRowCount: number;
	detectedDelimiter?: string; // Para CSV
	hasHeaders: boolean;
	warnings: string[]; // Ej: "Columna 'precio' tiene 5% valores no numÃ©ricos"
}

interface ColumnDef {
	name: string;
	type: "VARCHAR" | "INTEGER" | "DOUBLE" | "BOOLEAN" | "TIMESTAMP" | "DATE";
	nullable: boolean;
	uniqueValues?: number; // Estimado de valores Ãºnicos
	nullCount?: number; // Cantidad de nulos en sample
}
```

```typescript
// src/validators/schema-inferrer.ts
class SchemaInferrer {
  // Inferir tipo de columna analizando valores
  inferColumnType(values: any[]): ColumnType {
    // Prioridad: INTEGER > DOUBLE > BOOLEAN > TIMESTAMP > DATE > VARCHAR
    // Si >90% de valores son de un tipo, usar ese tipo
    // Si hay mezcla, usar VARCHAR
  }

  // Generar reporte de calidad de datos
  generateQualityReport(schema: InferredSchema, data: any[]): DataQualityReport {
    return {
      totalRows: data.length,
      columns: schema.columns.map(col => ({
        name: col.name,
        type: col.type,
        nullPercentage: ...,
        uniquePercentage: ...,
        issues: [...]  // "12 valores no pueden convertirse a INTEGER"
      }))
    };
  }
}
```

**Formatos soportados:**

| Formato | Parser         | Ventaja                     |
| ------- | -------------- | --------------------------- |
| CSV     | `csv-parse`    | Universal, flexible         |
| TSV     | `csv-parse`    | Tabular sin comillas        |
| JSON    | Nativo Node.js | Estructurado, nested        |
| JSONL   | Nativo Node.js | Streaming, archivos grandes |
| Parquet | DuckDB nativo  | 10x mÃ¡s rÃ¡pido, columnar    |

---

### Fase 5: Sistema de Exporters âœ…

**Tiempo estimado: 2 horas** | **Estado: COMPLETADO**

- [x] Crear interface `DataExporter` (vÃ­a `exporter-factory.ts`)
- [x] Implementar `CSVExporter` (RFC 4180 compliant)
- [x] Implementar `JSONExporter` (pretty-printed)
- [x] Implementar `JSONLExporter` (streaming-friendly)
- [x] Implementar `MarkdownExporter` (GFM tables)
- [x] Implementar `FileWriter` con validaciÃ³n de paths
- [x] Respetar `security.readOnly` de config

```typescript
// src/exporters/base-exporter.ts
interface DataExporter {
	readonly format: string;

	// Exportar solo si config.security.readOnly === false
	export(
		data: any[],
		outputPath: string,
		options?: ExporterOptions,
	): Promise<ExportResult>;

	// Siempre disponible: devolver como string (para mostrar en respuesta)
	serialize(data: any[], options?: ExporterOptions): string;
}

interface ExportResult {
	outputPath: string;
	rowCount: number;
	fileSize: number; // bytes
}
```

**Formatos de exportaciÃ³n:**

| Formato | Exporter        | Uso                         |
| ------- | --------------- | --------------------------- |
| CSV     | `CSVExporter`   | Compatibilidad universal    |
| JSON    | `JSONExporter`  | APIs, aplicaciones web      |
| JSONL   | `JSONLExporter` | Streaming, archivos grandes |

---

### Fase 6: Herramientas MCP âœ…

**Tiempo estimado: 3-4 horas** | **Estado: COMPLETADO**

Todas las tools respetan la configuraciÃ³n de seguridad y lÃ­mites.

**Tools implementadas:**
| Tool | DescripciÃ³n | Estado |
|------|-------------|--------|
| `load_data` | Cargar CSV/JSON/TSV en DuckDB | âœ… |
| `query_data` | SQL + traducciÃ³n NL bÃ¡sica | âœ… |
| `describe_data` | EstadÃ­sticas y schema | âœ… |
| `list_tables` | Listar tablas cargadas | âœ… |
| `export_data` | Exportar a CSV/JSON/JSONL/MD | âœ… |
| `visualize_data` | Charts ASCII y Mermaid | âœ… |

#### Tool 1: `load_data`

```typescript
// Carga un archivo en DuckDB (valida rutas y tamaÃ±o)
{
  name: "load_data",
  description: "Carga un archivo de datos en memoria para anÃ¡lisis",
  parameters: {
    filePath: string,       // Ruta al archivo (validada contra allowedPaths)
    tableName?: string,     // Nombre de la tabla (default: nombre del archivo)
    options?: {
      delimiter?: string,   // Para CSV (default: auto-detect)
      hasHeaders?: boolean, // Para CSV (default: true)
      validateSchema?: boolean  // Mostrar reporte de calidad (default: true)
    }
  },
  returns: {
    tableName: string,
    columns: ColumnDef[],
    rowCount: number,
    schemaReport?: DataQualityReport  // Si validateSchema: true
  },
  errors: [
    "Ruta no permitida por configuraciÃ³n",
    "Archivo excede tamaÃ±o mÃ¡ximo (100 MB)",
    "MÃ¡ximo de tablas alcanzado (10)"
  ]
}
```

#### Tool 2: `query_data`

```typescript
// Ejecuta consultas SQL o en lenguaje natural (con lÃ­mites)
{
  name: "query_data",
  description: "Consulta los datos usando SQL o lenguaje natural",
  parameters: {
    query: string,          // SQL o consulta en lenguaje natural
    format?: "table" | "json" | "csv"  // Formato de salida
  },
  returns: {
    results: any[],         // MÃ¡ximo config.limits.maxRowsOutput filas
    rowCount: number,       // Total de filas (antes de lÃ­mite)
    truncated: boolean,     // true si se aplicÃ³ lÃ­mite
    sql?: string            // SQL generado (si fue NL)
  },
  errors: [
    "SQL contiene keywords bloqueados: DROP",
    "Query timeout (30s)",
    "Tabla 'xxx' no existe"
  ]
}
```

#### Tool 3: `describe_data`

```typescript
// Obtiene estadÃ­sticas de una tabla o columna
{
  name: "describe_data",
  description: "Muestra estadÃ­sticas descriptivas de los datos",
  parameters: {
    tableName: string,
    column?: string         // Si se omite, describe toda la tabla
  },
  returns: {
    // Para tabla: resumen general + schema
    // Para columna numÃ©rica: min, max, avg, sum, count, percentiles
    // Para columna texto: valores Ãºnicos, top 10 mÃ¡s frecuentes
  }
}
```

#### Tool 4: `list_tables`

```typescript
// Lista todas las tablas cargadas
{
  name: "list_tables",
  description: "Lista las tablas disponibles y sus esquemas",
  parameters: {},
  returns: {
    tables: Array<{
      name: string,
      columns: ColumnDef[],
      rowCount: number,
      loadedAt: string      // ISO timestamp
    }>,
    limits: {
      current: number,
      max: number           // config.limits.maxTablesLoaded
    }
  }
}
```

#### Tool 5: `export_data`

```typescript
// Exporta datos (solo si readOnly: false en config)
{
  name: "export_data",
  description: "Exporta una tabla o resultado de query a un archivo",
  parameters: {
    outputPath: string,              // Ruta del archivo (validada)
    format: "csv" | "json" | "jsonl",
    source: {
      tableName?: string,
      query?: string
    },
    options?: {
      delimiter?: string,
      pretty?: boolean
    }
  },
  returns: {
    outputPath: string,
    rowCount: number,
    fileSize: string
  },
  errors: [
    "ExportaciÃ³n deshabilitada (readOnly: true)",
    "Ruta de salida no permitida"
  ]
}
```

**Casos de uso de transformaciÃ³n:**

```
# CSV â†’ JSON
load_data(filePath: "datos.csv")
export_data(source: {tableName: "datos"}, outputPath: "datos.json", format: "json")

# JSON â†’ CSV con transformaciÃ³n
load_data(filePath: "usuarios.json")
export_data(
  source: {query: "SELECT id, nombre, email FROM usuarios WHERE activo = 1"},
  outputPath: "usuarios_activos.csv",
  format: "csv"
)

# Merge mÃºltiples archivos
load_data(filePath: "ventas_2024.csv", tableName: "v1")
load_data(filePath: "ventas_2025.csv", tableName: "v2")
export_data(
  source: {query: "SELECT * FROM v1 UNION ALL SELECT * FROM v2"},
  outputPath: "ventas_total.json",
  format: "json"
)
```

---

### Fase 7: Traductor NL â†’ SQL âœ…

**Tiempo estimado: 2-3 horas** | **Estado: COMPLETADO (bÃ¡sico)**

- [x] Detectar si el input es SQL directo o lenguaje natural
- [x] Pattern matching para operaciones comunes
- [x] Generar SQL vÃ¡lido desde patrones

**Implementado en `query-data.ts` con patrones:**

- `show all` â†’ `SELECT * FROM table`
- `count by X` â†’ `SELECT X, COUNT(*) FROM table GROUP BY X`
- `top N by X` â†’ `SELECT * FROM table ORDER BY X DESC LIMIT N`
- `average/sum/min/max of X` â†’ Agregaciones
- `where X = Y` â†’ Filtros bÃ¡sicos

```typescript
// src/nlp/query-builder.ts
class QueryBuilder {
	translateToSQL(naturalQuery: string, schema: TableSchema): string;
}
```

**Patrones soportados:**

| Lenguaje Natural               | SQL Generado                                                  |
| ------------------------------ | ------------------------------------------------------------- |
| "promedio de ventas"           | `SELECT AVG(ventas) FROM table`                               |
| "suma de precio por categorÃ­a" | `SELECT categoria, SUM(precio) FROM table GROUP BY categoria` |
| "ventas mayores a 1000"        | `SELECT * FROM table WHERE ventas > 1000`                     |
| "top 10 por ingresos"          | `SELECT * FROM table ORDER BY ingresos DESC LIMIT 10`         |
| "contar por regiÃ³n"            | `SELECT region, COUNT(*) FROM table GROUP BY region`          |
| "donde nombre contiene 'Juan'" | `SELECT * FROM table WHERE nombre LIKE '%Juan%'`              |

**Nota:** Si el usuario escribe SQL vÃ¡lido, se ejecuta directamente sin traducciÃ³n.

---

### Fase 8: Sistema de VisualizaciÃ³n âœ…

**Tiempo estimado: 2-3 horas** | **Estado: COMPLETADO**

- [x] Crear interface `DataVisualizer` (integrado en `visualize-data.ts`)
- [x] Implementar `ASCIICharts` (barras horizontales, distribuciÃ³n, lÃ­neas)
- [x] Implementar `MermaidCharts` (pie, bar, line)
- [x] Auto-seleccionar tipo de grÃ¡fico segÃºn datos
- [x] Line charts para series temporales

```typescript
// src/visualizers/base-visualizer.ts
interface DataVisualizer {
	readonly format: "ascii" | "mermaid";
	render(data: ChartData, options?: ChartOptions): string;
}

interface ChartData {
	labels: string[];
	values: number[];
	title?: string;
}

interface ChartOptions {
	width?: number; // Para ASCII
	showValues?: boolean; // Mostrar nÃºmeros
	showPercentages?: boolean; // Para pie charts
}
```

**Tipos de grÃ¡ficos soportados:**

| Tipo                | ASCII | Mermaid | Uso ideal               |
| ------------------- | ----- | ------- | ----------------------- |
| Barras horizontales | âœ…    | âœ…      | Comparar categorÃ­as     |
| Pie/Donut           | âŒ    | âœ…      | DistribuciÃ³n porcentual |
| LÃ­neas              | âŒ    | âœ…      | Series temporales       |
| Histograma          | âœ…    | âœ…      | DistribuciÃ³n de valores |
| Tabla resumida      | âœ…    | âŒ      | EstadÃ­sticas rÃ¡pidas    |

#### Tool 6: `visualize_data`

```typescript
// Genera visualizaciones de datos
{
  name: "visualize_data",
  description: "Genera grÃ¡ficos ASCII o Mermaid de los datos",
  parameters: {
    source: {
      tableName?: string,          // Visualizar columna(s) de tabla
      query?: string               // O resultado de query SQL
    },
    chartType: "bar" | "pie" | "line" | "histogram" | "summary",
    format: "ascii" | "mermaid",   // Default: "ascii"
    options?: {
      title?: string,
      xColumn?: string,            // Columna para eje X / labels
      yColumn?: string,            // Columna para eje Y / valores
      width?: number,              // Ancho para ASCII (default: 40)
      limit?: number               // MÃ¡ximo de categorÃ­as (default: 10)
    }
  },
  returns: {
    chart: string,                 // El grÃ¡fico generado
    format: string,
    dataPoints: number
  }
}
```

**Ejemplos de salida:**

````
# ASCII Bar Chart
Ventas por RegiÃ³n:

Norte   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 45,230 (33%)
Sur     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 38,120 (28%)
Centro  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 52,890 (39%)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         0        25k       50k

# Mermaid Pie Chart (se renderiza en Claude/GitHub)
```mermaid
pie title Ventas por RegiÃ³n
    "Norte" : 45230
    "Sur" : 38120
    "Centro" : 52890
````

# Mermaid Bar Chart

```mermaid
xychart-beta
    title "Ventas Mensuales"
    x-axis [Ene, Feb, Mar, Abr, May]
    y-axis "Ventas" 0 --> 100000
    bar [45000, 52000, 48000, 61000, 58000]
```

````

---

### Fase 9: Testing y DocumentaciÃ³n âœ…
**Tiempo estimado: 2-3 horas** | **Estado: COMPLETADO**

- [x] Crear archivos de prueba (CSV, JSON) - tests manuales realizados
- [x] Tests unitarios para parsers (vitest) - 26 tests
- [x] Tests unitarios para DataStore (vitest) - 17 tests
- [x] Tests para parser-factory (vitest) - 14 tests
- [x] Total: 62 tests pasando
- [x] Documentar uso en README
- [x] Crear configuraciÃ³n para Claude Desktop
- [x] Crear configuraciÃ³n para VS Code + Copilot
- [x] Migrar de ESLint a Biome (0 vulnerabilidades)

---

## ğŸ› ï¸ Dependencias

```json
{
  "dependencies": {
    "@duckdb/node-api": "^1.4.4-r.1",
    "@modelcontextprotocol/sdk": "^1.0.0",
    "csv-parse": "^6.1.0",
    "zod": "^3.24.0"
  },
  "devDependencies": {
    "@biomejs/biome": "^2.4.3",
    "@types/node": "^22.13.0",
    "typescript": "^5.7.0",
    "vitest": "^3.0.0"
  }
}
```

**Actualizado:** 20 Feb 2026 - Migrado a Biome (linter + formatter), eliminadas 12 vulnerabilidades de ESLint.`

**Nota sobre DuckDB:**

- Soporte nativo para Parquet (no requiere dependencia adicional)
- 10-100x mÃ¡s rÃ¡pido que SQLite para agregaciones
- Bajo consumo de memoria con streaming

---

## ğŸ“Š Ejemplos de Uso

### Ejemplo 1: Cargar con validaciÃ³n de esquema

```
Usuario: "Carga el archivo ventas.csv"
MCP: âœ“ Tabla 'ventas' creada: 1,500 filas, 8 columnas

     ğŸ“‹ Esquema inferido:
     | Columna  | Tipo      | Nulos | Ãšnicos |
     |----------|-----------|-------|--------|
     | fecha    | DATE      | 0     | 365    |
     | producto | VARCHAR   | 0     | 45     |
     | cantidad | INTEGER   | 0     | 100    |
     | precio   | DOUBLE    | 12    | 234    |
     | cliente  | VARCHAR   | 5     | 180    |
     | regiÃ³n   | VARCHAR   | 0     | 3      |
     | vendedor | VARCHAR   | 0     | 12     |
     | total    | DOUBLE    | 0     | 890    |

     âš ï¸ Advertencias de calidad:
     - precio: 12 valores nulos (0.8%)
     - cliente: 5 valores nulos (0.3%)

Usuario: "SELECT regiÃ³n, SUM(total) FROM ventas GROUP BY regiÃ³n"
MCP:
| regiÃ³n  | SUM(total)  |
|---------|-------------|
| Norte   | 45230.00    |
| Sur     | 38120.00    |
| Centro  | 52890.00    |

Usuario: "total de ventas por regiÃ³n"  (lenguaje natural)
MCP: (mismo resultado, SQL generado automÃ¡ticamente)
```

### Ejemplo 2: MÃºltiples archivos con JOIN

```
Usuario: "Carga clientes.json como clientes"
MCP: âœ“ Tabla 'clientes' creada: 200 filas

Usuario: "Carga pedidos.csv como pedidos"
MCP: âœ“ Tabla 'pedidos' creada: 5,000 filas

Usuario: "SELECT c.nombre, SUM(p.total)
          FROM pedidos p
          JOIN clientes c ON p.cliente_id = c.id
          GROUP BY c.nombre
          ORDER BY SUM(p.total) DESC
          LIMIT 5"
MCP: Top 5 clientes por volumen de compras...
```

### Ejemplo 3: EstadÃ­sticas descriptivas

```
Usuario: "Describe la tabla ventas"
MCP: Tabla 'ventas':
     - Filas: 1,500
     - Columnas: 8

     | Columna  | Tipo    | Nulos | Ãšnicos |
     |----------|---------|-------|--------|
     | fecha    | TEXT    | 0     | 365    |
     | producto | TEXT    | 0     | 45     |
     | cantidad | INTEGER | 0     | 100    |
     | precio   | REAL    | 12    | 234    |
     ...

Usuario: "Describe la columna precio de ventas"
MCP: Columna 'precio' (REAL):
     - Registros: 1,500
     - Nulos: 12
     - Min: 5.99
     - Max: 2499.00
     - Promedio: 156.32
     - Mediana: 89.99
     - Desv. Std: 203.45
```

### Ejemplo 4: TransformaciÃ³n entre formatos

```
# CSV â†’ JSON simple
Usuario: "Carga datos.csv"
MCP: âœ“ Tabla 'datos' creada: 500 filas

Usuario: "Exporta datos a salida.json como JSON"
MCP: âœ“ Archivo exportado: salida.json (45.2 KB, 500 filas)

# CSV â†’ JSON con transformaciÃ³n SQL
Usuario: "Exporta los productos con precio > 100 a productos_premium.json"
MCP: âœ“ Ejecutando: SELECT * FROM datos WHERE precio > 100
     âœ“ Archivo exportado: productos_premium.json (12.1 KB, 89 filas)

# Merge mÃºltiples CSVs â†’ JSONL
Usuario: "Carga ventas_enero.csv como v1"
Usuario: "Carga ventas_febrero.csv como v2"
Usuario: "Exporta SELECT * FROM v1 UNION ALL SELECT * FROM v2 a ventas_q1.jsonl"
MCP: âœ“ Archivo exportado: ventas_q1.jsonl (234.5 KB, 3,200 filas)

# JSON â†’ CSV
Usuario: "Carga usuarios.json"
Usuario: "Exporta usuarios a usuarios.csv como CSV"
MCP: âœ“ Archivo exportado: usuarios.csv (18.3 KB, 200 filas)
```

### Ejemplo 5: VisualizaciÃ³n de datos

````

# GrÃ¡fico ASCII de barras

Usuario: "Visualiza ventas por regiÃ³n como barras ASCII"
MCP:
Ventas por RegiÃ³n:

Norte â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 45,230 (33%)
Sur â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 38,120 (28%)
Centro â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 52,890 (39%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
0 25k 50k

# GrÃ¡fico Mermaid pie (se renderiza en Claude/VS Code)

Usuario: "Muestra la distribuciÃ³n de ventas como pie chart en Mermaid"
MCP:

```mermaid
pie title DistribuciÃ³n de Ventas por RegiÃ³n
    "Norte" : 45230
    "Sur" : 38120
    "Centro" : 52890
```

# Histograma ASCII de precios

Usuario: "Histograma de la columna precio"
MCP:
DistribuciÃ³n de precios (n=1500):

0-50 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 312
50-100 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 534
100-200 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 401
200-500 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 198
500+ â–ˆâ–ˆâ–ˆ 55

# GrÃ¡fico de lÃ­neas Mermaid

Usuario: "GrÃ¡fico de lÃ­neas de ventas mensuales en Mermaid"
MCP:

```mermaid
xychart-beta
    title "Ventas Mensuales 2025"
    x-axis [Ene, Feb, Mar, Abr, May, Jun]
    y-axis "Total ($)" 0 --> 70000
    line [45000, 52000, 48000, 61000, 58000, 67000]
```

```

### Ejemplo 6: Seguridad en acciÃ³n (3 niveles)
```

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ğŸ”´ HARDCODED (no configurable - siempre bloqueado)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Intento de SQL destructivo (SIEMPRE bloqueado, sin importar config)

Usuario: "DROP TABLE ventas"
MCP: âŒ Error: SQL bloqueado por seguridad (hardcoded)
'DROP' no estÃ¡ permitido y no es configurable.

# Path traversal (SIEMPRE bloqueado)

Usuario: "Carga ../../../etc/passwd"
MCP: âŒ Error: Path traversal bloqueado por seguridad (hardcoded)
'../' no estÃ¡ permitido.

# Archivo sensible (SIEMPRE bloqueado)

Usuario: "Carga .env"
MCP: âŒ Error: Archivo bloqueado por seguridad (hardcoded)
'.env' estÃ¡ en lista de archivos protegidos.

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ğŸŸ¡ CONFIGURABLE CON ADVERTENCIA

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Intento de exportar con readOnly: true (configurable)

Usuario: "Exporta ventas a /tmp/ventas.csv"
MCP: âŒ Error: ExportaciÃ³n a disco deshabilitada (readOnly: true)
Para habilitar, configure "security.readOnly": false
âš ï¸ Advertencia: esto permite escribir archivos en disco.

# Ruta fuera de allowedPaths (configurable)

Usuario: "Carga /var/log/syslog"
MCP: âŒ Error: Ruta '/var/log/syslog' no estÃ¡ en rutas permitidas.
Rutas configuradas: ./data, ~/Documents/data
Puede ampliar allowedPaths en mini-mcp.config.json

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ğŸŸ¢ LÃMITES FLEXIBLES (libremente configurable)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Query que excede lÃ­mite de filas

Usuario: "SELECT \* FROM ventas_grandes"
MCP: âš ï¸ Resultado truncado: mostrando 1,000 de 50,000 filas
(lÃ­mite: maxRowsOutput = 1000, configurable)

     | id | fecha | ... |
     |----|-------|-----|
     ...

# Timeout en query larga

Usuario: "SELECT \* FROM tabla_enorme CROSS JOIN otra_tabla"
MCP: âŒ Error: Query excediÃ³ timeout (30s)
(lÃ­mite: queryTimeoutMs = 30000, configurable)
Sugerencia: Use LIMIT o filtre los datos

# MÃ¡ximo de tablas alcanzado

Usuario: "Carga archivo11.csv"
MCP: âŒ Error: MÃ¡ximo de tablas alcanzado (10/10)
(lÃ­mite: maxTablesLoaded = 10, configurable)
Use list_tables para ver tablas cargadas

````

---

## ğŸš€ Extensiones Futuras

| Feature | DescripciÃ³n | Prioridad |
|---------|-------------|-----------|
| **Excel Parser** | Soporte para .xlsx/.xls con `xlsx` | Alta |
| **HTTP/S3 Sources** | Cargar desde URLs y buckets | Media |
| **SVG Export** | Exportar grÃ¡ficos como SVG | Media |
| **NLP avanzado** | Usar LLM para queries complejos | Baja |
| **Excel Exporter** | Exportar a .xlsx | Baja |
| **CÃ³digo Python** | Generar cÃ³digo matplotlib | Baja |

---

## â±ï¸ Timeline Estimado

| Fase | DescripciÃ³n | DuraciÃ³n | Acumulado |
|------|-------------|----------|-----------|
| 1 | ConfiguraciÃ³n Base | 2h | 2h |
| 2 | Sistema de ConfiguraciÃ³n | 2h | 4h |
| 3 | DataStore DuckDB | 3h | 7h |
| 4 | Parsers + ValidaciÃ³n Esquema | 3h | 10h |
| 5 | Sistema de Exporters | 2h | 12h |
| 6 | Tools MCP | 4h | 16h |
| 7 | Traductor NL â†’ SQL | 3h | 19h |
| 8 | Sistema de VisualizaciÃ³n | 3h | 22h |
| 9 | Testing y Docs | 3h | 25h |

**Total estimado: ~22-28 horas de desarrollo**

---

## ğŸ“ Notas TÃ©cnicas

### Seguridad en 3 Niveles

| Nivel | ProtecciÃ³n | Ejemplo |
|-------|------------|---------|
| ğŸ”´ **Hardcoded** | No configurable, siempre activo | `DROP`, `DELETE`, path traversal |
| ğŸŸ¡ **Con advertencia** | Configurable, muestra warning | `readOnly`, `allowNetworkPaths` |
| ğŸŸ¢ **Flexible** | Sin restricciÃ³n | `maxRowsOutput`, `queryTimeoutMs` |

**Principio**: El usuario tiene control, pero no puede hacerse daÃ±o irreversible accidentalmente.

### Protecciones Hardcoded (no desactivables)
- SQL peligroso: `DROP`, `DELETE`, `TRUNCATE`, `ALTER`, `CREATE`, `INSERT`, `UPDATE`
- Paths sensibles: `../`, `.env`, `.git`, `~/.ssh`, `/etc/passwd`
- SanitizaciÃ³n de nombres de tabla
- LÃ­mites absolutos mÃ¡ximos

### Rendimiento
- **DuckDB** es 10-100x mÃ¡s rÃ¡pido que SQLite para agregaciones
- **Parquet nativo** - carga directa sin conversiÃ³n
- **Streaming** - JSONL para archivos grandes
- **LÃ­mite de memoria** configurable para DuckDB

### Calidad de Datos
- **Inferencia de esquema** antes de carga completa
- **Reporte de calidad** - % nulos, tipos inconsistentes
- **ValidaciÃ³n** - warnings para datos problemÃ¡ticos

### ConfiguraciÃ³n
- Archivo `mini-mcp.config.json` en raÃ­z del proyecto
- Valores por defecto seguros (read-only, rutas limitadas)
- Advertencias al iniciar si hay configuraciones riesgosas
- Errores si hay configuraciones inconsistentes

### Formatos
- **Entrada**: CSV, TSV, JSON, JSONL, Parquet
- **Salida**: CSV, JSON, JSONL, Markdown
- **VisualizaciÃ³n**: ASCII (terminal), Mermaid (markdown)

---

## ğŸ–¥ï¸ ConfiguraciÃ³n del Servidor

### Requisitos Previos

```bash
# Clonar e instalar
git clone https://github.com/jrodrigopuca/mini-mcp.git
cd mini-mcp
npm install
npm run build
````

### ConfiguraciÃ³n en Claude Desktop

1. **Localizar archivo de configuraciÃ³n:**
   - **macOS**: `~/Library/Application Support/Claude/claude_desktop_config.json`
   - **Windows**: `%APPDATA%\Claude\claude_desktop_config.json`
   - **Linux**: `~/.config/Claude/claude_desktop_config.json`

2. **Agregar mini-mcp al archivo:**

```json
{
	"mcpServers": {
		"mini-mcp": {
			"command": "node",
			"args": ["/ruta/completa/a/mini-mcp/dist/index.js"],
			"env": {}
		}
	}
}
```

3. **Ejemplo con ruta absoluta (macOS):**

```json
{
	"mcpServers": {
		"mini-mcp": {
			"command": "node",
			"args": ["/Users/tu-usuario/Developer/mini-mcp/dist/index.js"],
			"env": {}
		}
	}
}
```

4. **Reiniciar Claude Desktop** para que cargue el servidor.

5. **Verificar:** En Claude, deberÃ­as ver las herramientas disponibles:
   - `load_data` - Cargar archivos CSV/JSON
   - `query_data` - Consultas SQL o lenguaje natural
   - `describe_data` - EstadÃ­sticas de tablas
   - `list_tables` - Listar tablas cargadas
   - `export_data` - Exportar resultados
   - `visualize_data` - Crear grÃ¡ficos

---

### ConfiguraciÃ³n en VS Code con GitHub Copilot

1. **Instalar extensiÃ³n MCP:**
   - Buscar "MCP" en el marketplace de VS Code
   - O instalar `GitHub Copilot` que incluye soporte MCP

2. **Configurar en settings.json de VS Code:**

   Abrir `Preferences: Open User Settings (JSON)` y agregar:

```json
{
	"github.copilot.chat.mcpServers": {
		"mini-mcp": {
			"command": "node",
			"args": ["/ruta/completa/a/mini-mcp/dist/index.js"]
		}
	}
}
```

3. **Alternativa: Archivo `.vscode/mcp.json` en el workspace:**

```json
{
	"servers": {
		"mini-mcp": {
			"command": "node",
			"args": ["${workspaceFolder}/../mini-mcp/dist/index.js"]
		}
	}
}
```

4. **Usar con Copilot Chat:**
   - Abrir Copilot Chat (`Cmd+Shift+I` / `Ctrl+Shift+I`)
   - Las herramientas MCP estarÃ¡n disponibles automÃ¡ticamente
   - Ejemplo: "Carga el archivo data.csv y muÃ©strame las primeras 10 filas"

---

### ConfiguraciÃ³n Personalizada

Crear `mini-mcp.config.json` en el directorio de trabajo:

```json
{
	"security": {
		"readOnly": true,
		"allowedPaths": ["./data", "/Users/tu-usuario/Documents"],
		"maxFileSizeMB": 100,
		"allowNetworkPaths": false
	},
	"limits": {
		"maxRowsOutput": 1000,
		"maxTablesLoaded": 10
	},
	"duckdb": {
		"memoryLimitMB": 512,
		"threads": 2
	}
}
```

---

### VerificaciÃ³n de InstalaciÃ³n

```bash
# Probar que el servidor inicia correctamente
cd /ruta/a/mini-mcp
node dist/index.js

# DeberÃ­as ver:
# Loaded config from: ...
# DuckDB initialized: memory=512MB, threads=2
# Mini-MCP server started
```

---

## ğŸ“Š Resumen de Progreso

| Fase | DescripciÃ³n              | Estado        |
| ---- | ------------------------ | ------------- |
| 1    | ConfiguraciÃ³n Base       | âœ… Completado |
| 2    | Sistema de ConfiguraciÃ³n | âœ… Completado |
| 3    | DataStore DuckDB         | âœ… Completado |
| 4    | Parsers + ValidaciÃ³n     | âœ… Completado |
| 5    | Sistema de Exporters     | âœ… Completado |
| 6    | Tools MCP                | âœ… Completado |
| 7    | Traductor NL â†’ SQL       | âœ… Completado |
| 8    | VisualizaciÃ³n            | âœ… Completado |
| 9    | Testing y Docs           | âœ… Completado |

**Progreso total: 100% completado** ğŸ‰

**EstadÃ­sticas:**

- 62 tests pasando (vitest)
- 0 vulnerabilidades (npm audit)
- Soporte: CSV, TSV, JSON, JSONL, Parquet
- 6 herramientas MCP funcionales

```

```
